import statistics
import os
from src.lib.geodesic import ground_distance
from src.models.nav_data_model import NavDataModel
from src.core.database_file_parser_types import *
from src.core.database_creator_errors import *

# This file contains functions used for parsing a WTP file which contains data about public transport in Warsaw.
# Data generated by these functions if leter used for generating database used in 'PA jak Podjade' app.
# WTP data file has an organised structure. File is divided into sections, where each one stars with '*<two-letter Id of section>'
# and ends with '#<ID section>'. File has following sections (in order of apperance in file):
# TY - describes types of days
# KA* - describes which day is of what type
# KD - describes which type of day is used for creating a schedule for given line on given day
# ZA - describes stop complexes
# ZP - describes stop complexes in detiail. This section coontains a subsection:
#   PR - For each stop complex, this section describes individual stops of this complex
# SM - describes two-letter abbreviation used for indexing town in which stop complexes are.
# LL - describes each line. This section has subsections:
#   TR - describes each variant of line. Has subsections:
#       LW - describes route of given variant.
#       RP* - for each stop in this variant, describe departure times. Has subsection:
#           TD* - splits departure times by the day type in which they are used. Has subsection:
#               WG* - Show departue times of this variant, on this stop and during given type of day
#               OD* - Like WG, but contains much more details
#           OP* - contains additional informations for WG section. WG and OP sections together are used to show information for passengres in real life
#   WK - Shows each departure time of each course and variant on each avalible day type on each stop of this line.
#
# (* menas that this section is not used in app's database)

def get_raw_lines_of_text(section_name: str, text_lines : List[str], start_symbol="*", end_symbol="#", start_index=0) -> Union[Tuple[List[str], int], None]:
    """
    From the list of strings <text_lies> find line which contains symbol <start_symbol><section_name>, then find line wich contains
    sybmol <end_symbol><section_name> and return all linees which are between these two lines (without them).

    Args:
        section_name (str): ID of section which will be found
        text_lines (List[str]): list of string on which function will be searching for data of section
        start_symbol (str, optional): symbol which is defined as a starting symbol of section. Defaults to "*".
        end_symbol (str, optional): symbol which is defined as a ending symbol of section. Defaults to "#".
        start_index (int, optional): Index from which the function will start searching for given section. Defaults to 0.

    Returns:
        Union[Tuple[List[str], int], None]: lines within this section and index of line in <text_lines> where this section ends. Function will return None if it could not find a section
    """
    if start_index >= len(text_lines):
        raise WorkingIndexOutOfRange(get_raw_lines_of_text.__name__)
    start_string = start_symbol + section_name
    end_string = end_symbol + section_name
    data = []
    for index, line in enumerate(text_lines[start_index:]):
        if start_string in line:
            index += start_index + 1
            while True:
                line = text_lines[index]
                if end_string in line:
                    return data, index
                data.append(line)
                index += 1

def get_raw_lines_of_handle(section_name: str, handle: IO, start_index: int, start_symbol="*", end_symbol="#") -> Union[Tuple[List[str], int], None]:
    """
    From the file handle <handle> find line which contains symbol <start_symbol><section_name>, then find line wich contains
    sybmol <end_symbol><section_name> and return all linees which are between these two lines (without them).

    Args:
        section_name (str): ID of section which will be found
        handle (IO): file handle on which function will be searching for data of section
        start_index (int): Index from which the function will start searching for given section.
        start_symbol (str, optional): symbol which is defined as a starting symbol of section. Defaults to "*".
        end_symbol (str, optional): symbol which is defined as a ending symbol of section. Defaults to "#".

    Returns:
        Union[Tuple[List[str], int], None]: lines within this section and index of line in <handle> where this section ends. Function will return None if it could not find a section
    """
    start_string = start_symbol + section_name
    end_string = end_symbol + section_name
    data = []
    if start_index > os.stat(handle.name).st_size:
        raise WorkingIndexOutOfRange(get_raw_lines_of_handle.__name__)
    handle.seek(start_index)
    while True:
        line = handle.readline()
        if not line:
            return None
        if start_string in line:
            while True:
                line = handle.readline()
                if end_string in line:
                    return data, handle.tell()
                data.append(line)

def get_raw_data_stop_complex(handle: IO, start_index: int) -> Tuple[StopComplexParsedData, int]:
    """ Get data from data file <handle> which will be inserted into Stop_Complex table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[StopComplexParsedData, int]: Data for Stop_Complex table, which is a list of lists: [complex_ID, complex_name, id_of_town]. Function also returns index where the section of data ends.
    """

    raw_data = get_raw_lines_of_handle("ZA", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError("ZA")
    raw_stops, end_index = raw_data

    parsed_raw_stops = []

    ID_START = 3
    ID_END = 7
    STOP_NAME_START = 10
    STOP_NAME_END = 46
    TOWN_SHORT_START = 46
    TOWN_SHORT_END = 48

    for data in raw_stops:

        id = data[ID_START:ID_END]
        stop_name = data[STOP_NAME_START:STOP_NAME_END]
        town_short = data[TOWN_SHORT_START:TOWN_SHORT_END]

        check_if_var_is_integer(id)

        parsed_data = [int(id), stop_name.strip(", "), town_short]
        parsed_raw_stops.append(parsed_data)

    return parsed_raw_stops, end_index

def get_raw_data_stop(handle: IO, start_index: int) -> Tuple[StopParsedData, int]:
    """Get data from data file <handle> which will be inserted into Stop_Complex table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[StopParsedData, int]: Data for Stop table, which is a list of lists: [stop_ID, stop_ID_within_complex, stop_complex_ID, latitude, longitude, name_of_street, name_of_direction].
        Function also returns index where the section of data ends.
    """
    raw_data = get_raw_lines_of_handle("ZP", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError("ZP")

    raw_detailed_stops_lines, end_index = raw_data
    current_index = 0
    all_stop_raw_data = []
    all_stop_data = []
    parsed_all_stop_data = []

    STOP_ID_START = 9
    STOP_ID_END = 15
    STOP_NUMBER_START = 13
    STOP_NUMBER_END = 15
    STOP_COMPLEX_ID_START = 9
    STOP_COMPLEX_ID_END = 13
    LATITUDE_START = 111
    LATITUDE_END = 126
    LONGITUDE_START = 128
    LONGITUDE_END = 143
    STREET_START = 33
    STREET_END = 68
    DIRECTION_START = 74
    DIRECTION_END = 109

    while True:
        data = get_raw_lines_of_text("PR", raw_detailed_stops_lines, start_index=current_index)
        if not data:
            break
        stop_data, current_index = data
        all_stop_raw_data.append(stop_data)

    for stop_complex in all_stop_raw_data:
        single_stop_data = []
        for index, text_line in enumerate(stop_complex):
            data_len = len(stop_complex)
            if text_line[STOP_ID_START:STOP_ID_END].isnumeric():
                single_stop_data.append(text_line)
                temp_index = index + 1
                while not stop_complex[temp_index][STOP_ID_START:STOP_ID_END].isnumeric():
                    single_stop_data.append(stop_complex[temp_index])
                    temp_index += 1
                    if temp_index == data_len:
                        break
                parsed_all_stop_data.append(single_stop_data)
                single_stop_data = []


    for stop_data in parsed_all_stop_data:
        header = stop_data[0]
        stop_id = header[STOP_ID_START:STOP_ID_END]
        stop_number = header[STOP_NUMBER_START:STOP_NUMBER_END]
        stop_complex_id = header[STOP_COMPLEX_ID_START:STOP_COMPLEX_ID_END]
        latitude = header[LATITUDE_START:LATITUDE_END]
        longitude = header[LONGITUDE_START:LONGITUDE_END]
        street = header[STREET_START:STREET_END]
        direction = header[DIRECTION_START:DIRECTION_END]

        try:
            latitude = float(latitude)
        except ValueError as e:
            latitude = None

        try:
            longitude = float(longitude)
        except ValueError as e:
            longitude = None

        street = street.strip(" ,")
        direction = direction.strip(" ,")

        # if there is no direction, there ale only "*" given as direcion
        if all(char == "*" for char in direction):
            direction = None

        check_if_var_is_integer(stop_id)
        check_if_var_is_integer(stop_complex_id)

        all_stop_data.append([int(stop_id), stop_number, int(stop_complex_id), latitude, longitude, street, direction])

    return all_stop_data, end_index

def get_raw_variant_and_line_data(handle: IO, start_index: int) -> Tuple[VaraintParsedData, LineParsedData, int]:
    """Get data from data file <handle> which will be inserted into Varaint and Line tables in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[VaraintParsedData, LineParsedData, int]: Data for Variant table, which is a list of lists: [line_of_variant,
        variant_name, direction_ID, level_within_direction, direction_description, flag_is_this_variant_basic] and
        data for Line table which is list of lists: [line_name, line_type_description]
        Function also returns index where the section of data ends.
    """
    basic_variants = []
    all_variants = []
    all_lines = []
    additional_variants = []

    raw_data = get_raw_lines_of_handle("LL", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError("LL")
    data, end_index = raw_data

    index = 0
    current_line = ""

    VARIANT_ID_START = 9
    VARIANT_ID_END = 17
    LINE_NUMBER_ROW_OFFSET = 4
    VARIANT_DATA_ROW_OFFSET = 2
    LINE_NUMBER_START = 9
    LINE_NUMBER_END = 15
    DIRECTION_DESC_START = 64
    DIRECTION_DESC_END = 98
    DIRECTION_START = 113
    DIRECTION_END = 114
    DIRECTION_LEVEL_START = 121
    DIRECTION_LEVEL_END = -1
    COURSE_ID_START = 9
    COURSE_ID_END = 26
    LINE_DESCRIPTION_START = 16
    LINE_DESCRIPTION_END = -1

    def get_variants_list_from_courses(line_number: str, text_index: int) -> VaraintParsedData:
        """Get special (non-basic) varians of this line. Because these are not as well-described as basic,
        information about them is being created based on entries in 'list of courses' section.

        Args:
            line_number (str): line name from which data about special variants will be created
            text_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
            the section begins, but must be smaller or equal tha index of section.

        Returns:
            VaraintParsedData: List of special Variants, but only line, variant_name are returned (other data is set to None). Also, flag is_basic is set to 0.
        """
        line_course_list, _ = get_raw_lines_of_text("WK", data, start_index=text_index)
        line_course_list = [line[COURSE_ID_START:COURSE_ID_END] for line in line_course_list]
        variants = [line.split("/")[0] for line in line_course_list]
        variants = set(variants)
        return [[line_number, variant, None, None, None, 0] for variant in variants]

    while True:
        raw_data = get_raw_lines_of_text("LW", data, start_index=index)
        if not raw_data:
            break
        raw_stops, new_index = raw_data
        if data[new_index-len(raw_stops)-LINE_NUMBER_ROW_OFFSET].split()[0] == 'Linia:':
            offset = new_index-len(raw_stops)-LINE_NUMBER_ROW_OFFSET
            current_line = data[offset][LINE_NUMBER_START:LINE_NUMBER_END].strip(" ")
            line_desc = data[offset][LINE_DESCRIPTION_START:LINE_DESCRIPTION_END].strip(" ")
            all_lines.append([current_line, line_desc])
            all_variants += get_variants_list_from_courses(current_line, new_index)

        variant_data_line = data[new_index-len(raw_stops)-VARIANT_DATA_ROW_OFFSET]


        variant_id      = variant_data_line[VARIANT_ID_START:VARIANT_ID_END].strip(" ")
        direction_desc  = variant_data_line[DIRECTION_DESC_START:DIRECTION_DESC_END].strip(", ")
        direction       = variant_data_line[DIRECTION_START:DIRECTION_END]
        direction_level = variant_data_line[DIRECTION_LEVEL_START:DIRECTION_LEVEL_END].strip(" ")

        check_if_var_is_integer(direction_level)

        basic_variants.append([current_line, variant_id, direction, int(direction_level), direction_desc, 1])
        index = new_index

    variant_check = [(variant[0], variant[1]) for variant in basic_variants]
    for additional_variant in all_variants:
        if (additional_variant[0], additional_variant[1]) not in variant_check:
            additional_variants.append(additional_variant)

    return basic_variants+additional_variants, all_lines, end_index

def get_previous_line_with(string_to_find: str, data: List[str], index: int) -> str:
    """From list of sring <data> find the line which contains <straing_to_find>.
    The searching starts at index <index> of <data> and goes upwards to the beginning of the file.

    Args:
        string_to_find (str): string to find
        data (List[str]): list of straing, where <string_to_find> will be searched
        index (int): index where teh searching starts.

    Returns:
        str: line of text which contains the first occurence of <string_to_find>
    """
    while index >= 0:
        current_line = data[index]
        if string_to_find in current_line:
            return current_line
        index -= 1

def get_raw_data_stop_course(handle: IO, start_index: int, course_id_dict: Dict[Tuple[str, str], int], stop_raw_data: StopParsedData) -> Tuple[StopCourseParsedData, int]:
    """Get data from data file <handle> which will be inserted into Stop_Course table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.
        course_id_dict (Dict[Tuple[str, str], int]): Dict where keys are tuples of lines and unique courses of that line and
        values are numeric indexes of these courses. This dict must be created by get_dict_for_stop_course() function.
        stop_raw_data (StopParsedData): data about stops, used for splitting stop_course data into chunks based of position of stop and time of departure.
        This data must be generated by get_raw_data_stop() function.

    Returns:
        Tuple[StopCourseParsedData, int]:  Data for StopCourse table, which is a list of lists: [course_ID, stop_ID, departure_time_in_minutes]
        Function also returns index where the section of data ends.
    """

    index = 0

    raw_data = get_raw_lines_of_handle("LL", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError('LL')
    data, end_index = raw_data

    all_data = []

    SINGLE_COURSE_ID_START = 9
    SINGLE_COURSE_ID_END = 26
    STOP_ID_START = 28
    STOP_ID_END = 34
    TIME_START = 37
    TIME_END = 43
    STOP_PARSED_DATA_STOP_ID_INDEX = 0
    STOP_PARSED_DATA_STOP_LATITUDE = 3
    STOP_PARSED_DATA_STOP_LONGITUDE = 4

    line_number = ""
    while True:
        raw_data = get_raw_lines_of_text("WK", data, start_index=index)
        if not raw_data:
            break
        raw_times, new_index = raw_data
        index = new_index
        line_number = get_previous_line_with("Linia:", data, index).split()[1]
        for line in raw_times:
            single_course_id = line[SINGLE_COURSE_ID_START:SINGLE_COURSE_ID_END]
            check_if_var_is_integer(line[STOP_ID_START:STOP_ID_END])
            stop_id = int(line[STOP_ID_START:STOP_ID_END])
            time = time_str_to_int(line[TIME_START:TIME_END].strip(" "))

            all_data.append([course_id_dict[(line_number, single_course_id)], stop_id, time])

    # Add chunk ID of stop course to data

    stop_dict = {}
    for stop in stop_raw_data:
        stop_dict[stop[STOP_PARSED_DATA_STOP_ID_INDEX]] = (stop[STOP_PARSED_DATA_STOP_LATITUDE],stop[STOP_PARSED_DATA_STOP_LONGITUDE])
    all_data_with_chunks = []
    for stop_course in all_data:
        course_id, stop_id, time = stop_course
        latitude, longitude = stop_dict[stop_id]
        stop_course = [course_id, stop_id, time, NavDataModel.get_chunk_from_location_and_time((latitude, longitude), time*60)]
        all_data_with_chunks.append(stop_course)

    return all_data_with_chunks, end_index

def get_stop_neighbours(data: StopParsedData, walk_distance=250, min_neighbours=5) -> StopNeighbourParsedData:
    """Get data which will be inserted into Stop_Neighbour table in database.
    This function will return all Stops which are within distance of <walk_distance> meters, or closest <min_neighbours> stops
    from this stops, if stops within distance of <walk_distance> are less than <min_neighbours>
    Args:
        data (StopParsedData): data about stops, created by get_raw_data_stop() function
        walk_distance (int, optional): maximum distance in meters from which stop is considered as neighbour. Defaults to 250.
        min_neighbours (int, optional): minimal number of neighbours. Defaults to 5.

    Returns:
        StopNeighbourParsedData: Tuple[StopCourseParsedData, int]:  Data for Stop_Neighbour table, which is a list of lists:
        [stop_id, neighbout_id, distance_in_meters_between_these_two]
    """
    STOP_ID = 0
    STOP_COMPLEX_ID = 2
    LATITUDE = 3
    LONGITUDE = 4
    def approximate_location(stop_complex_id: int) -> Tuple[float, float]:
        if stop_complex_id < 0:
            raise StopIDOutOfRange()
        all_lat = []
        all_long = []
        for stop_data in data:
            if stop_data[STOP_COMPLEX_ID] == stop_complex_id and stop_data[LATITUDE] is not None:
                all_lat.append(stop_data[LATITUDE])
                all_long.append(stop_data[LONGITUDE])
        if len(all_lat) == 0:
            # if no data is found, approx this stop coordinates to previous stop complex coordinattes
            return approximate_location(stop_complex_id-1)
        return statistics.mean(all_lat), statistics.mean(all_long)

    all_neighbours = []
    for stop_data in data:
        stop_neighbours = []
        dist_data = []

        if stop_data[LATITUDE]:
            stop_lat, stop_long = stop_data[LATITUDE], stop_data[LONGITUDE]
        else:
            stop_lat, stop_long = approximate_location(stop_data[STOP_COMPLEX_ID])

        for neighbour_data in data:

            if neighbour_data[STOP_ID] == stop_data[STOP_ID]:
                continue

            if neighbour_data[LATITUDE]:
                neigh_lat, neigh_long = neighbour_data[LATITUDE], neighbour_data[LONGITUDE]
            else:
                neigh_lat, neigh_long = approximate_location(neighbour_data[STOP_COMPLEX_ID])

            distance = ground_distance((stop_lat, stop_long), (neigh_lat, neigh_long))
            if distance <= walk_distance:
                stop_neighbours.append((neighbour_data[STOP_ID], distance))
            dist_data.append((neighbour_data[STOP_ID], distance))

        if len(stop_neighbours) < min_neighbours:
            stop_neighbours = sorted(dist_data, key= lambda x: x[1])[:min_neighbours]

        for neighbour in stop_neighbours:
            all_neighbours.append((stop_data[STOP_ID], neighbour[0], round(neighbour[1], 6)))

    return all_neighbours

def get_raw_data_stop_variant(handle: IO, stops_list : List[int], special_variants_list: VaraintParsedData, start_index: int) -> StopVaraintParsedData:
    """Get data from data file <handle> which will be inserted into Stop_Varaint table in database.

    Args:
        handle (IO): data file hanlde
        stops_list (List[int]): list of stops, generated by get_foreign_keys_for_stop_variant() function.
        special_variants_list (VaraintParsedData): List of special variants, generated by get_foreign_keys_for_stop_variant() function.
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        StopVaraintParsedData:  Data for Stop_Variant table, which is a list of lists:
        [variant_line, variant_name, order_of_stop_in_variant, stop_id, flag_is_stop_on_request, zone_number]
        Function also returns index where the section of data ends.
    """
    raw_data = get_raw_lines_of_handle("LL", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError("LL")
    data, end_index = raw_data
    index = 0
    current_line = ""
    current_zone = 1
    all_stop_basic_variants = []
    all_stop_special_variants = []

    def get_stop_from_special_variants(line: str, index: int) -> StopVaraintParsedData:
        """Get data about Stop_variant for variants which are special. From these varaints, data about its route is stored only
        in 'list of stops and courses departures' section.

        Args:
            line (str): line from which data about special variants will be generated
            index (int): index from which this function will start looking for appropriate section.

        Returns:
            StopVaraintParsedData: Data for Stop_Variant table generated for special variants.
        """
        special_variants_line = [variant for variant in special_variants_list if variant[0] == line]
        all_stop_courses, _ = get_raw_lines_of_text("WK", data, start_index=index)
        all_stop_courses = [stop_course.split() for stop_course in all_stop_courses]
        line_stop_special_variants = []
        used_special_variants = []
        working_index = 0
        data_size = len(all_stop_courses)

        while True:
            if working_index == data_size:
                break
            current_text_line = all_stop_courses[working_index]
            variant_index = current_text_line[0].split("/")[0]
            if variant_index not in used_special_variants and (line, variant_index) in special_variants_line:
                stop_order = 1
                current_course = current_text_line[0]
                while working_index != data_size and current_course == all_stop_courses[working_index][0]:
                    current_stop = all_stop_courses[working_index][1]
                    check_if_var_is_integer(current_stop)
                    current_stop = int(current_stop)
                    if current_stop in stops_list:
                        line_stop_special_variants.append([line, variant_index, stop_order, current_stop, None, None])
                        stop_order += 1
                    working_index += 1
                used_special_variants.append(variant_index)
                if len(used_special_variants) == len(special_variants_line):
                    break
                continue
            working_index += 1
        return line_stop_special_variants


    LINE_NUMBER_ROW_OFFSET = 4
    LINE_NUMBER_START = 9
    LINE_NUMBER_END = 15
    VARIANT_DATA_ROW_OFFSET = 2
    VARIANT_ID_START = 9
    VARIANT_ID_END = 17
    ZONE_CHECK_START = 15
    ZONE_CHECK_END = 45
    STOP_ID_START = 49
    STOP_ID_END = 55
    ON_REQUEST_START = 96
    ON_REQUEST_END = 98
    ON_REQUEST_STRING = "NŻ"
    FIRST_ZONE_CHECK  = ("""====== S T R E F A   1 =======""", 1)
    SECOND_ZONE_CHECK = ("""====== S T R E F A   2 =======""", 2)
    ZONES = [FIRST_ZONE_CHECK, SECOND_ZONE_CHECK]

    while True:
        raw_data = get_raw_lines_of_text("LW", data, start_index=index)
        if not raw_data:
            break
        raw_stops, index = raw_data

        if data[index-len(raw_stops)-LINE_NUMBER_ROW_OFFSET].split()[0] == 'Linia:':
            current_line = data[index-len(raw_stops)-LINE_NUMBER_ROW_OFFSET][LINE_NUMBER_START:LINE_NUMBER_END].strip(" ")
            all_stop_special_variants += get_stop_from_special_variants(current_line, index)

        variant_data_line = data[index-len(raw_stops)-VARIANT_DATA_ROW_OFFSET]
        variant_id = variant_data_line[VARIANT_ID_START:VARIANT_ID_END].strip(" ")

        current_zone = 1
        stop_order = 1

        for text_line in raw_stops:

            zone_check = text_line[ZONE_CHECK_START:ZONE_CHECK_END]
            for zone in ZONES:
                if zone_check == zone[0]:
                    current_zone = zone[1]
                    break

            stop_id = text_line[STOP_ID_START:STOP_ID_END]
            if not stop_id.isnumeric():
                continue

            check_if_var_is_integer(stop_id)
            stop_id = int(stop_id)
            if stop_id not in stops_list:
                continue

            on_request = 1 if text_line[ON_REQUEST_START:ON_REQUEST_END] == ON_REQUEST_STRING else 0
            stop_variant_data = [current_line, variant_id, stop_order, int(stop_id), on_request, current_zone]
            stop_order += 1
            all_stop_basic_variants.append(stop_variant_data)

    return all_stop_basic_variants+all_stop_special_variants, end_index


def get_foreign_keys_for_stop_variant(parsed_data_stop : StopParsedData, parsed_data_variant: VaraintParsedData) -> Tuple[List[int], VaraintParsedData]:
    """Get data which will be required for creating Stop_Variant data: list of all IDs of Stops, and
    list of (line, variant_name) of all variants, which are flagged as special.

    Args:
        parsed_data_stop (StopParsedData): data about stops created by get_raw_data_stop() function
        parsed_data_variant (VaraintParsedData): data about variants created by get_raw_data_variant() function

    Returns:
        Tuple[List[int], VaraintParsedData]: list of all IDs of Stops and list of all special variants.
    """
    STOP_ID_POSITION = 0
    LINE_ID_POITION = 0
    VARIANT_ID_POSITION = 1
    IS_BASIC_POSITION = 5
    stop_list = [data[STOP_ID_POSITION] for data in parsed_data_stop]
    special_variant_list = [(data[LINE_ID_POITION], data[VARIANT_ID_POSITION]) for data in parsed_data_variant if data[IS_BASIC_POSITION] == 0]

    return stop_list, special_variant_list

def get_raw_data_course(handle: IO, index: int) -> Tuple[CourseParsedData, int]:
    """Get data from data file <handle> which will be inserted into Course table in database.

    Args:
        handle (IO): data file hanlde
        index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[CourseParsedData, int]: Data for Course table, which is a list of lists:
        [line_name, variant_name, day_tpe_of_course, hour_of_start_of_course]
        Function also returns index where the section of data ends.
    """

    TIME_INDEX = 3
    COURSE_NAME_START = 9
    COURSE_NAME_END = 26
    LINE_NAME_START = 9
    LINE_NAME_END = 15
    all_courses = []

    raw_data = get_raw_lines_of_handle("LL", handle, index)
    if not raw_data:
        raise SectionNotFoundError()
    all_data, _  = raw_data

    working_index = 0

    while True:
        raw_data = get_raw_lines_of_text("WK", all_data, start_index=working_index)
        if not raw_data:
            break
        data, working_index = raw_data

        text_line_with_bus_line = get_previous_line_with("Linia:", all_data, working_index)
        current_line = text_line_with_bus_line[LINE_NAME_START:LINE_NAME_END].strip()

        data = [line[COURSE_NAME_START:COURSE_NAME_END] for line in data]
        data = set(data)
        data = [line.strip("_").split("/") for line in data]
        data = [[current_line] + text_line for text_line in data]
        times = [line.pop(TIME_INDEX) for line in data]
        for index, line in enumerate(data):
            time_in_minutes = time_str_to_int(times[index])
            line.append(time_in_minutes)
        all_courses += data

    return all_courses, working_index

def get_dict_for_stop_course(raw_course_data: CourseParsedData) -> Dict[Tuple[str, str], int]:
    """From data about courses return the dict, where keys are names of courses and values are new enumerated
    indexes of these courses.

    Args:
        raw_course_data (CourseParsedData): data about courses created by get_raw_data_course() function

    Returns:
        Dict[Tuple[str, str], int]: Dict, where keys are names of courses (line_number and course_id) and values are new enumerated
    indexes of these courses.
    """
    course_dict = {}
    LINE_INDEX = 0
    VARIANT_NAME_INDEX = 1
    DAY_TYPE_INDEX = 2
    START_HOUR_INDEX = 3
    index = 1
    for line in raw_course_data:
        course_name = f"{line[VARIANT_NAME_INDEX]}/{line[DAY_TYPE_INDEX]}/{time_int_to_str(line[START_HOUR_INDEX])}"
        course_name = f"{course_name:_<17}"
        course_dict[(line[LINE_INDEX], course_name)] = index
        index += 1

    return course_dict

def time_str_to_int(time_string: str) -> int:
    """ Change from String where data about hour is stored: 'HH:mm' amonut of minutes from midnight as integer.

    Args:
        time_string (str): String (formatted as 'HH:mm') where data about hour is stored

    Returns:
        int: amonut of minutes from midnight
    """
    MINUTES_IN_HOUR = 60
    hour, minutes = time_string.split(".")
    check_if_var_is_integer(hour)
    check_if_var_is_integer(minutes)
    time_in_minutes = int(hour) * MINUTES_IN_HOUR + int(minutes)

    return time_in_minutes

def time_int_to_str(time_int: int) -> str:
    """Change amount of minutes from midnight to a String where data about hour is stored as 'HH:mm'

    Args:
        time_int (int): amonut of minutes from midnight

    Returns:
        str:String where data about hour is stored using format 'HH:mm'
    """

    hour = time_int//60
    hour_str = hour if hour >= 10 else f"0{hour}"

    minutes = time_int%60
    minutes_str = minutes if minutes >= 10 else f"0{minutes}"

    time_str = f"{hour_str}.{minutes_str}"
    return time_str

def change_stop_and_variant_places(stop_raw_data: StopParsedData, variant_raw_data: VaraintParsedData) -> Tuple[StopNormalizedData, VariantNormalizedData, PlaceParsedData]:
    """Chagne raw data of streets and directions of stops and dir_descriptions of varaints from their names to IDs. Return changed stop_data and varaint_data
    as well as list of places (streets, directions  and dir_descriptions combined)

    Args:
        stop_raw_data (StopParsedData): data about stops generated by get_raw_data_stop() function
        variant_raw_data (VaraintParsedData): data about variants generated by get_raw_data_variant_and_line() function

    Returns:
        Tuple[StopNormalizedData, VariantNormalizedData, PlaceParsedData]: list of lists representing stops, where Streets and Directions were
        replaced by ID of these places, list of lists representing variants, where dir_descriptions were replaced by Id of these places, and a list
        where each element is a list [enumerated_index, place_name].
    """
    STREET_INDEX = 5
    DIRECTION_INDEX = 6
    VARIANT_DESCRIPTION_INDEX = 4
    streets = [line[STREET_INDEX] for line in stop_raw_data]
    directions = [line[DIRECTION_INDEX] for line in stop_raw_data]
    dir_desc = [line[VARIANT_DESCRIPTION_INDEX] for line in variant_raw_data]

    raw_places = streets + directions + dir_desc
    places_dict = create_dict_of_object_index(raw_places)

    parsed_stops = replace_object_in_list_with_index(stop_raw_data, places_dict, [STREET_INDEX, DIRECTION_INDEX])
    parsed_variants = replace_object_in_list_with_index(variant_raw_data, places_dict, [VARIANT_DESCRIPTION_INDEX])

    return parsed_stops, parsed_variants, dict_of_indexes_to_list(places_dict)

def parse_line_data(raw_line_data: LineParsedData) -> Tuple[LineNormalizedData, LineTypeParsedData]:
    """Split Line raw data into two tables: one with (line_id, type_id), second with (type_id, type_desc)

    Args:
        raw_line_data (LineParsedData): line data, generated by get_raw_data_line() function

    Returns:
        Tuple[LineNormalizedData, LineTypeParsedData]: two lists of lists: first with [line_id, type_id],
        second with [type_id, type_desc]
    """
    TYPE_INDEX = 1
    types = [line[TYPE_INDEX] for line in raw_line_data]
    types_dict = create_dict_of_object_index(types, ordered=True)
    parsed_lines = replace_object_in_list_with_index(raw_line_data, types_dict, [TYPE_INDEX])
    return parsed_lines, dict_of_indexes_to_list(types_dict)

def create_dict_of_object_index(data_table: List[Any], ordered=False) -> Dict[Any, int]:
    """Return dict: dict[object] = index from data_table, which consists list of objects to map to dict

    Args:
        data_table (List[Any]): List of objects, which will be mapped into dict
        ordered (bool, optional): if True, the entries in dict will be in the same order as are the first occurences of objects in <data_table>. Defaults to False.

    Returns:
        Dict[Any, int]: Dict, where keys are unique items from <data_table> and values are enumerated numbers.
    """
    data_table = [data for data in data_table if data]
    objects_dict = {}
    if ordered:
        objects = []
        for object in data_table:
            if object not in objects:
                objects.append(object)
    else:
        objects = set(data_table)

    index = 1
    for object in objects:
        objects_dict[object] = index
        index += 1
    return objects_dict

def replace_object_in_list_with_index(data_table: List[Any], index_dict: Dict[Any, int], indexes_to_change: List[int]) -> List[Any]:
    """Return new data_table in which in each row object in indexes from indexes_to_chnage will be replaced with index from index_dict

    Args:
        data_table (List[Any]): data table to change
        index_dict (Dict[Any, int]): dict of (item: index) from which new data in columns in data_table will be created
        indexes_to_change (List[int]): indexes of items where from each entry from <data_table> individual items will be replaced by corresponding indexes from <index_dict>,

    Returns:
        List[Any]: updated data_table, where in each row under indexes from <index_to_change> there are now indexes of items from <index_dict>.
    """
    new_data_table = []
    for row in data_table:
        for index in indexes_to_change:
            object = row[index]
            row[index] = index_dict[object] if object else object
        new_data_table.append(row)
    return new_data_table

def dict_of_indexes_to_list(dict_to_change: Dict[Any, int]) -> List[Tuple[int, Any]]:
    """Return dict of dict[object] = index to a list with tuples (index, object)

    Args:
        dict_to_change (Dict[Any, int]): dict, where keys are objects and values are numbers

    Returns:
        List[Tuple[int, Any]]: list of tuples, where first element of each tuple has an old value from dict of a object, which is now a second element of tuple.
    """
    return list(zip(dict_to_change.values(), dict_to_change.keys()))


def get_raw_data_town(handle: IO, start_index: int) -> Tuple[TownParsedData, int]:
    """Get data from data file <handle> which will be inserted into Town table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[TownParsedData, int]: Data for Town table, which is a list of lists:
        [town_two-letter_ID, town_name]
        Function also returns index where the section of data ends.
    """
    TOWN_INDEX_START = 3
    TOWN_INDEX_END = 5
    TOWN_NAME_START = 8
    TOWN_NAME_END = -1
    # For some reason, index for Warsaw is not given in the 'SM' section
    WARSAW_ID   = '--'
    WARSAW_NAME = 'WARSZAWA'

    raw_data = get_raw_lines_of_handle("SM", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError()
    raw_town_data, end_index = raw_data

    all_towns = [[WARSAW_ID, WARSAW_NAME]]

    for line in raw_town_data:
        town_index = line[TOWN_INDEX_START:TOWN_INDEX_END]
        town_name = line[TOWN_NAME_START:TOWN_NAME_END].strip(" ")
        all_towns.append([town_index, town_name])

    return all_towns, end_index

def get_raw_data_day_type(handle: IO, start_index: int) -> Tuple[DayTypeParsedData ,int]:
    """Get data from data file <handle> which will be inserted into Day_Type table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.

    Returns:
        Tuple[DayTypeParsedData ,int]:  Data for Day_Type table, which is a list of lists:
        [day_type_two-letter_ID, day_type_description]
        Function also returns index where the section of data ends.
    """

    DAY_TYPE_ID_START = 3
    DAY_TYPE_ID_END   = 5
    DAY_TYPE_NAME_START = 8
    DAY_TYPE_NAME_END = -1
    all_day_types = []
    raw_data = get_raw_lines_of_handle("TY", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError()
    raw_day_type, end_index  = raw_data

    for line in raw_day_type:
        day_type_id = line[DAY_TYPE_ID_START:DAY_TYPE_ID_END]
        day_type_name = line[DAY_TYPE_NAME_START:DAY_TYPE_NAME_END].strip(" ")
        all_day_types.append([day_type_id, day_type_name])

    return all_day_types, end_index

def get_raw_data_day_line(handle: IO, start_index: int, lines_list: LinesList) -> Tuple[DayLineParsedData, int]:
    """Get data from data file <handle> which will be inserted into Day_Line table in database.

    Args:
        handle (IO): data file hanlde
        start_index (int): index from which this function will start looking for appropriate section. This param does not have to be exaclty where
        the section begins, but must be smaller or equal tha index of section.
        lines_list (LinesList): list of lines, generated by prepare_lies_list()

    Returns:
        Tuple[DayLineParsedData, int]: Data for Day_Line table, which is a list of lists:
        [day, line, day_type_which_will_be_on_this_lines_schelude_on_this_day]
        Function also returns index where the section of data ends.
    """

    def create_empty_day_line_dict() -> Dict[str, None]:
        """From each line in <lines_list> generate dict (line: None)

        Returns:
            Dict[str, None]: dict, where keys are lines, and every value is None
        """
        date_dict = {}
        for line in lines_list:
            date_dict[line] = None

        return date_dict

    def reshape_date_and_day_line_dict(date: str, day_line_dict: Dict[str, str]) -> List[Tuple[str, str, str]]:
        """Change date and dict[line] = day_type to list of [date, line, day_type]

        Args:
            date (str): date on which there will be given dict of day_types
            day_line_dict (Dict[str, str]): dict where keys are lines, and values are day types which
            will be on schelude of this particular <date>

        Returns:
            List[Tuple[str, str, str]]:  list of lists: [date, line, day_type]
        """
        DAY_TYPE_INDEX = 0
        LINE_INDEX = 1
        day_line_list = dict_of_indexes_to_list(day_line_dict)
        parsed_list = [[date, row[LINE_INDEX], row[DAY_TYPE_INDEX]] for row in day_line_list]

        return parsed_list

    raw_data = get_raw_lines_of_handle("KD", handle, start_index)
    if not raw_data:
        raise SectionNotFoundError()
    raw_day_line_data, end_index = raw_data

    DATE_START = 3
    DATE_END = 13
    NUMBER_OF_LINES_START = 14
    NUMBER_OF_LINES_END = -1
    LINE_START = 3
    LINE_END = 9
    DAY_TYPE_START = 12
    DAY_TYPE_END = 14
    all_day_lines = []

    data_len = len(raw_day_line_data)
    current_date = raw_day_line_data[0][DATE_START:DATE_END]
    next_date_index = raw_day_line_data[0][NUMBER_OF_LINES_START:NUMBER_OF_LINES_END].strip()
    check_if_var_is_integer(next_date_index)
    next_date_index = int(next_date_index) + 1
    current_index = 1
    current_date_day_line_types = create_empty_day_line_dict()

    while current_index < data_len:

        if current_index == next_date_index:
            all_day_lines += reshape_date_and_day_line_dict(current_date, current_date_day_line_types)
            current_date = raw_day_line_data[current_index][DATE_START:DATE_END]
            next_date_index_add = raw_day_line_data[current_index][NUMBER_OF_LINES_START:NUMBER_OF_LINES_END].strip()
            check_if_var_is_integer(next_date_index_add)
            next_date_index += int(next_date_index_add) + 1
            current_date_day_line_types = create_empty_day_line_dict()
            current_index += 1
            continue

        line = raw_day_line_data[current_index][LINE_START:LINE_END].strip(" ")
        day_type = raw_day_line_data[current_index][DAY_TYPE_START:DAY_TYPE_END]
        current_date_day_line_types[line] = day_type


        current_index += 1
    all_day_lines += reshape_date_and_day_line_dict(current_date, current_date_day_line_types)

    return all_day_lines, end_index

def prepare_line_list(raw_line_data: LineParsedData) -> LinesList:
    """From list of lists: [line_name, line_type] extract first column

    Args:
        raw_line_data (LineParsedData): line data generated by get_raw_data_line() function

    Returns:
        LinesList: list of line names from <raw_line_data>
    """
    LINE_INDEX = 0
    return [row[LINE_INDEX] for row in raw_line_data]

# This function is used in our database in order to fit our data in given quota and to simplify model of public transport.
def reduce_stop_course_data(stop_course_data: StopCourseParsedData, course_data: CourseParsedData, course_dict: Dict[str, int], lines_list: LinesList) -> StopCourseParsedData:
    """Reduce the amount of data in stop_course raw data to contain only courses from the type of day where the amount of courses is the biggest for given line.

    Args:
        stop_course_data (StopCourseParsedData): data about StopCourse generated by get_raw_data_stop_course
        course_data (CourseParsedData): data about courses generated by get_raw_data_course() function
        course_dict (Dict[str, int]): dict to map each course with given number. Geenerated by get_dict_for_stop_course() function
        lines_list (LinesList): list of lines, generated, by prepare_line_list() function

    Returns:
        StopCourseParsedData: data with type like <stop_course_data> but with data reduced to only contain courses from the type of day where the amount of courses is the biggest for given line.
    """
    COURSE_DATA_LINE_INDEX = 0
    COURSE_DATA_DAY_TYPE_INDEX = 2
    COURSE_DICT_LINE_INDEX = 0
    COURSE_DICT_COURSE_NAME_INDEX = 1
    COURSE_NAME_DAY_TYPE_INDEX = 1
    STOP_COURSE_COURSE_INDEX = 0

    line_most_common_type = {}
    courses_in_most_common_day_type = []

    # Count the most common type of day for each line
    for line in lines_list:
        day_type_list = [course[COURSE_DATA_DAY_TYPE_INDEX] for course in course_data if course[COURSE_DATA_LINE_INDEX] == line]
        most_common_day_type = max(set(day_type_list), key=day_type_list.count)
        line_most_common_type[line] = most_common_day_type

    # Get courses_id from courses which are taking place on the most common type of day
    for course in course_dict.keys():
        course_line = course[COURSE_DICT_LINE_INDEX]
        course_name = course[COURSE_DICT_COURSE_NAME_INDEX]
        course_day_type = course_name.split("/")[COURSE_NAME_DAY_TYPE_INDEX]
        if line_most_common_type[course_line] == course_day_type:
            courses_in_most_common_day_type.append(course_dict[course])


    # Change the stop_course_data to contain only the most common type
    courses_in_most_common_day_type = set(courses_in_most_common_day_type)
    new_stop_course = [stop_course for stop_course in stop_course_data if stop_course[STOP_COURSE_COURSE_INDEX] in courses_in_most_common_day_type]

    return new_stop_course

def check_if_var_is_integer(var_to_check: str) -> None:
    """Check if given data got from data file if integer.
    If not, raise an error. Otherwise do nothing.

    Args:
        var_to_check (str): value to check if it is Integer.

    Raises:
        NumericTypeExpectedError: when <var_to_check> is not an int.
    """
    if not var_to_check.isnumeric():
        raise NumericTypeExpectedError()
